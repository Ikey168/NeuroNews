.PHONY: help airflow-up airflow-down airflow-logs marquez-ui airflow-init airflow-status airflow-build airflow-test-openlineage

# Default target
help:
	@echo "NeuroNews Makefile"
	@echo ""
	@echo "Airflow & Marquez Orchestration:"
	@echo "  airflow-build    - Build custom Airflow image with OpenLineage"
	@echo "  airflow-up       - Start Airflow and Marquez services"
	@echo "  airflow-down     - Stop Airflow and Marquez services"
	@echo "  airflow-logs     - Show Airflow logs"
	@echo "  airflow-init     - Initialize Airflow (run once)"
	@echo "  airflow-status   - Show status of all services"
	@echo "  airflow-test-openlineage - Test OpenLineage integration"
	@echo "  airflow-test-env-config  - Test environment configuration (Issue #188)"
	@echo "  airflow-test-news-pipeline - Test news pipeline DAG (Issue #189)"
	@echo "  airflow-test-timezone-sla - Test timezone and SLA configuration (Issue #190)"
	@echo "  airflow-test-lineage-naming - Test lineage naming convention (Issue #193)"
	@echo "  airflow-bootstrap - Bootstrap Airflow connections and variables (Issue #194)"
	@echo "  airflow-test-bootstrap - Test bootstrap script functionality (Issue #194)"
	@echo "  marquez-ui       - Open Marquez UI in browser"
	@echo ""
	@echo "dbt Analytics:"
	@echo "  dbt-deps         - Install dbt packages"
	@echo "  dbt-build        - Build all dbt models"
	@echo "  dbt-build-snowflake - Build dbt models on Snowflake (no-op locally)"
	@echo "  dbt-docs         - Generate and serve dbt documentation"
	@echo "  dbt-test         - Run dbt tests"
	@echo "  dbt-clean        - Clean dbt artifacts"
	@echo ""
	@echo "URLs:"
	@echo "  Airflow UI:  http://localhost:8080 (airflow/airflow)"
	@echo "  Marquez UI:  http://localhost:3000"

# Airflow and Marquez orchestration targets

# Build custom Airflow image with OpenLineage (Issue #187)
airflow-build:
	@echo "ğŸ”¨ Building custom Airflow image with OpenLineage provider..."
	@cd docker/airflow && docker build -t neuronews/airflow:2.8.1-openlineage .
	@echo "âœ… Custom Airflow image built successfully!"
	@echo "ğŸ·ï¸  Image: neuronews/airflow:2.8.1-openlineage"

airflow-up:
	@echo "ğŸš€ Starting Airflow and Marquez services..."
	@cd docker/airflow && docker-compose -f docker-compose.airflow.yml up -d
	@echo ""
	@echo "âœ… Services started!"
	@echo "ğŸ“Š Airflow UI: http://localhost:8080 (username: airflow, password: airflow)"
	@echo "ğŸ“ˆ Marquez UI: http://localhost:3000"
	@echo ""
	@echo "Use 'make airflow-logs' to view logs"
	@echo "Use 'make airflow-status' to check service health"

airflow-down:
	@echo "ğŸ›‘ Stopping Airflow and Marquez services..."
	@cd docker/airflow && docker-compose -f docker-compose.airflow.yml down
	@echo "âœ… Services stopped!"

airflow-logs:
	@echo "ğŸ“‹ Showing Airflow logs..."
	@cd docker/airflow && docker-compose -f docker-compose.airflow.yml logs -f

airflow-init:
	@echo "ğŸ”§ Initializing Airflow..."
	@cd docker/airflow && docker-compose -f docker-compose.airflow.yml up airflow-init
	@echo "âœ… Airflow initialized!"

airflow-status:
	@echo "ğŸ“Š Service Status:"
	@cd docker/airflow && docker-compose -f docker-compose.airflow.yml ps

# Test OpenLineage integration (Issue #187)
airflow-test-openlineage:
	@echo "ğŸ§ª Testing OpenLineage integration..."
	@echo "1. Checking if services are running..."
	@cd docker/airflow && docker-compose -f docker-compose.airflow.yml ps
	@echo ""
	@echo "2. Triggering test DAG..."
	@cd docker/airflow && docker-compose -f docker-compose.airflow.yml exec airflow-webserver \
		airflow dags trigger test_openlineage_integration
	@echo ""
	@echo "3. Checking webserver logs for OpenLineage..."
	@echo "   Look for 'OpenLineage' messages in the logs:"
	@cd docker/airflow && docker-compose -f docker-compose.airflow.yml logs airflow-webserver | grep -i openlineage || echo "No OpenLineage logs found yet"
	@echo ""
	@echo "âœ… Test triggered! Check Airflow UI for DAG execution: http://localhost:8080"

# Test Airflow â†’ Marquez environment configuration (Issue #188)
airflow-test-env-config:
	@echo "ğŸ”§ Testing Airflow â†’ Marquez environment configuration..."
	@python3 demo/demo_airflow_marquez_env_config.py

# Test news pipeline DAG (Issue #189)
airflow-test-news-pipeline:
	@echo "ğŸ“° Testing news pipeline DAG..."
	@python3 demo/demo_news_pipeline_dag.py

# Test timezone and SLA configuration (Issue #190)
airflow-test-timezone-sla:
	@echo "ğŸ•°ï¸ Testing timezone and SLA configuration..."
	@python3 demo/demo_timezone_sla_config.py

# Test lineage naming convention (Issue #193)
airflow-test-lineage-naming:
	@echo "ğŸ”— Testing lineage naming convention..."
	@python3 demo/demo_lineage_naming.py

# Bootstrap Airflow connections and variables (Issue #194)
airflow-bootstrap:
	@echo "ğŸš€ Bootstrapping Airflow connections and variables..."
	@docker exec $$(docker-compose -f docker/airflow/docker-compose.airflow.yml ps -q airflow-webserver) bash -c 'cd /opt/airflow && ./scripts/airflow_bootstrap.sh --verbose'

# Test bootstrap script functionality (Issue #194)
airflow-test-bootstrap:
	@echo "ğŸ§ª Testing bootstrap script..."
	@python3 demo/demo_airflow_bootstrap.py

marquez-ui:
	@echo "ğŸŒ Opening Marquez UI..."
	@if command -v xdg-open > /dev/null; then \
		xdg-open http://localhost:3000; \
	elif command -v open > /dev/null; then \
		open http://localhost:3000; \
	else \
		echo "Please open http://localhost:3000 in your browser"; \
	fi

# Additional utility targets
airflow-webserver-logs:
	@cd docker/airflow && docker-compose -f docker-compose.airflow.yml logs -f airflow-webserver

airflow-scheduler-logs:
	@cd docker/airflow && docker-compose -f docker-compose.airflow.yml logs -f airflow-scheduler

marquez-logs:
	@cd docker/airflow && docker-compose -f docker-compose.airflow.yml logs -f marquez

airflow-clean:
	@echo "ğŸ§¹ Cleaning up Airflow volumes and containers..."
	@cd docker/airflow && docker-compose -f docker-compose.airflow.yml down -v
	@docker system prune -f
	@echo "âœ… Cleanup complete!"

# dbt Analytics targets (Issue #203)

dbt-deps:
	@echo "ğŸ“¦ Installing dbt packages..."
	@cd dbt/neuro_news && dbt deps --profiles-dir ../
	@echo "âœ… dbt packages installed!"

dbt-build:
	@echo "ğŸ”¨ Building all dbt models..."
	@cd dbt/neuro_news && dbt build --profiles-dir ../
	@echo "âœ… dbt models built successfully!"

dbt-build-snowflake:
	@echo "ğŸ”ï¸  Building dbt models on Snowflake..."
	@if [ -z "$$SNOWFLAKE_ACCOUNT" ]; then \
		echo "âš ï¸  SNOWFLAKE_ACCOUNT not set - skipping Snowflake build"; \
		echo "â„¹ï¸  This is expected in local development"; \
		echo "â„¹ï¸  To use Snowflake: uncomment target in profiles.yml and set env vars"; \
	else \
		echo "ğŸ”— Connecting to Snowflake account: $$SNOWFLAKE_ACCOUNT"; \
		cd dbt/neuro_news && dbt build --profiles-dir ../ --target prod; \
	fi

dbt-docs:
	@echo "ğŸ“š Generating dbt documentation..."
	@cd dbt/neuro_news && dbt docs generate --profiles-dir ../
	@echo "ğŸŒ Serving dbt documentation..."
	@cd dbt/neuro_news && dbt docs serve --profiles-dir ../

dbt-test:
	@echo "ğŸ§ª Running dbt tests..."
	@cd dbt/neuro_news && dbt test --profiles-dir ../

dbt-clean:
	@echo "ğŸ§¹ Cleaning dbt artifacts..."
	@cd dbt/neuro_news && dbt clean --profiles-dir ../
	@echo "âœ… dbt artifacts cleaned!"
