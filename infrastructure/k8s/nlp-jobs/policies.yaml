apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: neuronews-nlp-jobs-network-policy
  namespace: neuronews
  labels:
    app: neuronews-nlp
    component: security
spec:
  podSelector:
    matchLabels:
      app: neuronews-nlp
  policyTypes:
  - Ingress
  - Egress
  
  # Ingress rules
  ingress:
  # Allow metrics collection
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    - podSelector:
        matchLabels:
          app: prometheus
    ports:
    - protocol: TCP
      port: 8080
  
  # Allow health checks from kubelet
  - from: []
    ports:
    - protocol: TCP
      port: 8080
  
  # Egress rules
  egress:
  # Allow DNS resolution
  - to: []
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 53
  
  # Allow HTTPS for model downloads
  - to: []
    ports:
    - protocol: TCP
      port: 443
  
  # Allow HTTP for model downloads
  - to: []
    ports:
    - protocol: TCP
      port: 80
  
  # Allow Redshift connection
  - to: []
    ports:
    - protocol: TCP
      port: 5439
  
  # Allow PostgreSQL connection
  - to: []
    ports:
    - protocol: TCP
      port: 5432
  
  # Allow Kubernetes API access
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    ports:
    - protocol: TCP
      port: 443
  - to: []
    ports:
    - protocol: TCP
      port: 6443

---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: neuronews-nlp-jobs-quota
  namespace: neuronews
  labels:
    app: neuronews-nlp
    component: resource-management
spec:
  hard:
    # Job limits
    count/jobs.batch: "10"
    
    # Resource limits
    requests.cpu: "20"
    requests.memory: "40Gi"
    limits.cpu: "40"
    limits.memory: "80Gi"
    
    # GPU limits
    requests.nvidia.com/gpu: "4"
    limits.nvidia.com/gpu: "4"
    
    # Storage limits
    persistentvolumeclaims: "10"
    requests.storage: "500Gi"
    
    # Object limits
    configmaps: "20"
    secrets: "20"
    services: "10"

---
apiVersion: v1
kind: LimitRange
metadata:
  name: neuronews-nlp-jobs-limits
  namespace: neuronews
  labels:
    app: neuronews-nlp
    component: resource-management
spec:
  limits:
  # Container limits
  - type: Container
    default:
      cpu: "1000m"
      memory: "2Gi"
      nvidia.com/gpu: "0"
    defaultRequest:
      cpu: "100m"
      memory: "256Mi"
    max:
      cpu: "8000m"
      memory: "16Gi"
      nvidia.com/gpu: "2"
    min:
      cpu: "50m"
      memory: "128Mi"
  
  # Pod limits
  - type: Pod
    max:
      cpu: "8000m"
      memory: "16Gi"
      nvidia.com/gpu: "2"
    min:
      cpu: "50m"
      memory: "128Mi"
  
  # PVC limits
  - type: PersistentVolumeClaim
    max:
      storage: "200Gi"
    min:
      storage: "1Gi"

---
# Pod Security Policy (for clusters with PSP enabled)
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: neuronews-nlp-jobs-psp
  labels:
    app: neuronews-nlp
    component: security
spec:
  privileged: false
  allowPrivilegeEscalation: false
  requiredDropCapabilities:
    - ALL
  volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    - 'persistentVolumeClaim'
  runAsUser:
    rule: 'MustRunAsNonRoot'
  runAsGroup:
    rule: 'MustRunAs'
    ranges:
      - min: 1000
        max: 65535
  seLinux:
    rule: 'RunAsAny'
  fsGroup:
    rule: 'RunAsAny'

---
# GPU device plugin DaemonSet (for GPU acceleration)
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nvidia-device-plugin-daemonset
  namespace: kube-system
  labels:
    app: neuronews-nlp
    component: gpu-support
spec:
  selector:
    matchLabels:
      name: nvidia-device-plugin-ds
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        name: nvidia-device-plugin-ds
    spec:
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      priorityClassName: system-node-critical
      containers:
      - image: nvidia/k8s-device-plugin:v0.12.2
        name: nvidia-device-plugin-ctr
        args: ["--fail-on-init-error=false"]
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
        volumeMounts:
          - name: device-plugin
            mountPath: /var/lib/kubelet/device-plugins
      volumes:
        - name: device-plugin
          hostPath:
            path: /var/lib/kubelet/device-plugins
      nodeSelector:
        accelerator: nvidia

---
# Node affinity for GPU scheduling
apiVersion: v1
kind: ConfigMap
metadata:
  name: neuronews-nlp-node-config
  namespace: neuronews
  labels:
    app: neuronews-nlp
    component: scheduling
data:
  gpu-node-affinity.yaml: |
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: accelerator
              operator: In
              values: ["nvidia"]
            - key: node-type
              operator: In
              values: ["gpu-compute", "compute"]
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          preference:
            matchExpressions:
            - key: node-type
              operator: In
              values: ["gpu-compute"]
        - weight: 50
          preference:
            matchExpressions:
            - key: zone
              operator: In
              values: ["us-east-1a", "us-east-1b"]
  
  cpu-node-affinity.yaml: |
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchExpressions:
            - key: node-type
              operator: In
              values: ["compute", "cpu-compute"]
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          preference:
            matchExpressions:
            - key: instance-type
              operator: In
              values: ["c5.xlarge", "c5.2xlarge", "m5.xlarge"]

---
# HorizontalPodAutoscaler for job controller (if using a job controller)
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: neuronews-nlp-job-controller-hpa
  namespace: neuronews
  labels:
    app: neuronews-nlp
    component: autoscaling
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: neuronews-nlp-job-controller
  minReplicas: 1
  maxReplicas: 3
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
