# NeuroNews â€“ AI-Powered News Intelligence Pipeline

ğŸ“¡ **Real-Time ETL Pipeline for Politics & Technology News** | ğŸš€ **AI-Driven Insights** | ğŸ“Š **Sentiment & Trend Analysis**

---

## ğŸ” Overview

**NeuroNews** is an advanced **ETL pipeline** designed to **scrape, analyze, and visualize** politics and technology news using **AI-powered NLP, sentiment analysis, and knowledge graph-based insights**. Built on **AWS cloud infrastructure**, it enables **real-time event detection, entity linking, and customizable dashboards** for deeper news intelligence.

---

## âš¡ Features

âœ… **Automated News Scraping** â€“ Extracts articles from multiple sources using **Scrapy + Playwright/Selenium**.

âœ… **AI-Powered Event Detection** â€“ Clusters related news articles into significant political & tech events.

âœ… **NLP & Sentiment Analysis** â€“ Extracts **named entities, sentiment scores, and keyword trends**.

âœ… **Knowledge Graph Integration** â€“ Links entities, policies, and historical context using **AWS Neptune**.

âœ… **Custom Dashboards & Reports** â€“ Generates **interactive visualizations and AI-driven summaries**.

âœ… **Historical News Context** â€“ Tracks **timeline-based evolution** of news topics.

âœ… **API for Insights & Reporting** â€“ REST API for accessing structured **event summaries, trends, and sentiment data**.

âœ… **AWS Cloud Integration** â€“ Serverless processing with **AWS Lambda, Redshift, S3, Step Functions & SageMaker**.

---

## ğŸ“Œ Use Cases

ğŸ”¹ **Journalists & Analysts** â€“ Quickly access AI-generated summaries and sentiment shifts.

ğŸ”¹ **Policy Makers & Think Tanks** â€“ Track **legislative impact & policy evolution**.

ğŸ”¹ **Business Intelligence Teams** â€“ Analyze **tech industry trends & company sentiment**.

ğŸ”¹ **Researchers & Data Scientists** â€“ Leverage **knowledge graph insights & historical data**.

---

## ğŸ› ï¸ Tech Stack

ğŸ”¹ **Backend & Scraping**: Python, Scrapy, Selenium, Playwright, AWS Lambda
ğŸ”¹ **NLP & AI Models**: Hugging Face Transformers, AWS Comprehend, GPT-4, Pegasus
ğŸ”¹ **Database & Storage**: AWS Redshift, AWS Neptune (Graph DB), S3, DynamoDB
ğŸ”¹ **Event Detection & Summarization**: BERT Embeddings, k-Means Clustering
ğŸ”¹ **Visualization & Reporting**: AWS QuickSight, Streamlit, Matplotlib

---

## ğŸš€ Getting Started

### ğŸ“ Project Structure

This project is organized for clean development and maintenance. See [`docs/PROJECT_STRUCTURE.md`](docs/PROJECT_STRUCTURE.md) for a detailed overview of the directory structure and organization guidelines.

### 1ï¸âƒ£ Clone the Repository

```bash

git clone https://github.com/your-username/newsgraph-ai.git
cd newsgraph-ai

```text

### 2ï¸âƒ£ Install Dependencies

```bash

pip install -r requirements.txt

```text

### 3ï¸âƒ£ Docker Development (Recommended)

```bash

# Run with Docker Compose for development

docker compose up --build

# Run tests in containerized environment

docker compose -f docker-compose.test-minimal.yml up --build --abort-on-container-exit

```text

### 4ï¸âƒ£ Configure AWS Credentials

- Add your **AWS_ACCESS_KEY_ID** & **AWS_SECRET_ACCESS_KEY**.

- Ensure **IAM roles** have permissions for Lambda, S3, Redshift, and Neptune.

### 5ï¸âƒ£ Run Tests and Generate Coverage Report

Before running the test suite make sure the Terraform CLI is installed. On
Ubuntu you can install it from HashiCorp's APT repository:

```bash

sudo apt-get install -y gnupg software-properties-common curl
curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg
echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
sudo apt-get update && sudo apt-get install terraform

```text

This ensures the Terraform validation steps succeed.

```bash

# Initialize and validate the Terraform code just like the CI workflow

terraform -chdir=deployment/terraform init -backend=false
terraform -chdir=deployment/terraform validate

```text

```bash

# Run tests with coverage reporting

pytest

# View the coverage report

# Open coverage_report/index.html in your browser

```text

The coverage report provides:

- Line-by-line code coverage analysis

- Branch coverage statistics

- Untested code identification

- Module-level coverage summaries

### 6ï¸âƒ£ Run Demo Scripts

```bash

# Explore available demos

ls demo/

# Run specific demo (example)

python demo/demo_sentiment_pipeline.py

```text

### 7ï¸âƒ£ Run the Scraper

```bash

python src/scraper.py

```text

### 8ï¸âƒ£ Run the NLP Pipeline

```bash

python src/nlp_processor.py

```text

### 9ï¸âƒ£ Access Dashboards & Reports

- AWS QuickSight for **visualizations & insights**.

- REST API for **news sentiment, event tracking, and historical context**.

---

## ğŸ“… Roadmap

ğŸ›  **Phase 1:** Web Scraping & Data Ingestion âœ…

ğŸ›  **Phase 2:** NLP Processing & Sentiment Analysis âœ…

ğŸ›  **Phase 3:** Event Detection & AI Summarization âœ…

ğŸ›  **Phase 4:** Knowledge Graph & Deep Linking âœ…

ğŸ›  **Phase 5:** Interactive Dashboards & API Development âœ…

ğŸš€ **Future Expansion:** Predictive analytics, real-time fact-checking, blockchain-based news verification

---

## ğŸ“¬ Contact & Contributions

ğŸ”— **GitHub Issues:** Report bugs & request features.

ğŸ”— **Pull Requests:** Contributions welcome! See **CONTRIBUTING.md** for guidelines.

ğŸ“§ **Email:** ikey168@proton.me

ğŸ”– **License:** MIT

