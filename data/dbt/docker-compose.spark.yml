version: '3.8'

services:
  spark-master:
    image: bitnami/spark:3.4.2
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - "8080:8080"
      - "7077:7077"
    networks:
      - dbt-spark-network

  spark-worker:
    image: bitnami/spark:3.4.2
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - spark-master
    networks:
      - dbt-spark-network

  spark-thrift-server:
    image: bitnami/spark:3.4.2
    container_name: spark-thrift-server
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_URL=spark://spark-master:7077
    command: >
      /opt/bitnami/spark/bin/start-thriftserver.sh
      --master spark://spark-master:7077
      --conf spark.sql.warehouse.dir=/tmp/warehouse
      --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
      --conf spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkSessionCatalog
      --conf spark.sql.catalog.spark_catalog.type=hive
      --conf spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog
      --conf spark.sql.catalog.local.type=hadoop
      --conf spark.sql.catalog.local.warehouse=/tmp/warehouse
      --hiveconf javax.jdo.option.ConnectionURL=jdbc:derby:;databaseName=/tmp/metastore_db;create=true
      --hiveconf javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver
    ports:
      - "10000:10000"  # Thrift server port
      - "10001:10001"  # HTTP endpoint
      - "4040:4040"    # Spark UI
    depends_on:
      - spark-master
    volumes:
      - ./warehouse:/tmp/warehouse
      - ./metastore:/tmp/metastore_db
    networks:
      - dbt-spark-network

  # Optional: Hive Metastore for production use
  hive-metastore:
    image: apache/hive:3.1.3
    container_name: hive-metastore
    environment:
      - SERVICE_NAME=metastore
      - DB_DRIVER=postgres
      - SERVICE_OPTS=-Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres:5432/metastore -Djavax.jdo.option.ConnectionUserName=hive -Djavax.jdo.option.ConnectionPassword=hive
    ports:
      - "9083:9083"
    depends_on:
      - postgres
    networks:
      - dbt-spark-network

  postgres:
    image: postgres:13
    container_name: postgres-metastore
    environment:
      - POSTGRES_DB=metastore
      - POSTGRES_USER=hive
      - POSTGRES_PASSWORD=hive
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - dbt-spark-network

networks:
  dbt-spark-network:
    driver: bridge

volumes:
  postgres_data:
